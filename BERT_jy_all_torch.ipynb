{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT_jy_all_torch.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"8bd049ceebfa4a64a062245aeaddc8f5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4c1592caa0d44faeb4e8feb682bdb235","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_aa960860c4b0475d85d7806ce57978be","IPY_MODEL_a458ff71e9ab46cca01bffa14d8116f8"]}},"4c1592caa0d44faeb4e8feb682bdb235":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aa960860c4b0475d85d7806ce57978be":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_144fc1a1ebd54cd0b278bf95cd7fbd06","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":249928,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":249928,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_84906ccc049749868b0804275cea0753"}},"a458ff71e9ab46cca01bffa14d8116f8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1a1b35739c9e4e0abee8646c1eb0d2aa","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 250k/250k [00:01&lt;00:00, 185kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e56ff34d68db4abe9b13332c9ee21cf5"}},"144fc1a1ebd54cd0b278bf95cd7fbd06":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"84906ccc049749868b0804275cea0753":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1a1b35739c9e4e0abee8646c1eb0d2aa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e56ff34d68db4abe9b13332c9ee21cf5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"88f4d4d2a1e3458fb77c6ae1bf99f397":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9863fc90085a497aa466aead5289e4cf","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a3726900e24b442e874e509a712f2c22","IPY_MODEL_23e6cd0801e84695b377005559e0e681"]}},"9863fc90085a497aa466aead5289e4cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a3726900e24b442e874e509a712f2c22":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_460f1395d6e34bb08f482943f1fd8002","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":49,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":49,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d606f82bc41f4e74bf48550f11b0f8d7"}},"23e6cd0801e84695b377005559e0e681":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ef47f9f8bea04f95b624f2be80e0f9d7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 49.0/49.0 [00:00&lt;00:00, 190B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b6b0af86de524f90bd99bba20d02bc86"}},"460f1395d6e34bb08f482943f1fd8002":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d606f82bc41f4e74bf48550f11b0f8d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ef47f9f8bea04f95b624f2be80e0f9d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b6b0af86de524f90bd99bba20d02bc86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9dd9d8b532224501bed58ce9cf0388d3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b89b29e5626c427f8b4235470df3a2b7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_edfc0a7ca7a04cec94d8f9053f93d33b","IPY_MODEL_cceaacf04137468181a73bff4adca90c"]}},"b89b29e5626c427f8b4235470df3a2b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"edfc0a7ca7a04cec94d8f9053f93d33b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ea9cadd1202d4cbf94fdb432dd522a5a","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":672,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":672,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_56693297792c422f94586c67e997c0f2"}},"cceaacf04137468181a73bff4adca90c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_157314427389450eb82713915ef7cf63","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 672/672 [00:18&lt;00:00, 36.5B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_263a3c2fd58b43ad832eaf46feaa7168"}},"ea9cadd1202d4cbf94fdb432dd522a5a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"56693297792c422f94586c67e997c0f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"157314427389450eb82713915ef7cf63":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"263a3c2fd58b43ad832eaf46feaa7168":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3e2d035e75444449adda2c9a58b8246a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_93f653834c8a415a9e187d563a4fbf00","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7cdb3315d6e245268e1ef3eef44b865a","IPY_MODEL_46fc8ec5195e4ccda0c60e62ed62e3ed"]}},"93f653834c8a415a9e187d563a4fbf00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7cdb3315d6e245268e1ef3eef44b865a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_44686ceb370745f499ece85697d11f51","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1341992121,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1341992121,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f6229f3640eb437baa4b6d844071fd93"}},"46fc8ec5195e4ccda0c60e62ed62e3ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_eabbdab3a77c40fb9dd312447b81d0a5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.34G/1.34G [00:16&lt;00:00, 82.7MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c74ecfec7fa9436ba7ad95ea66d147a5"}},"44686ceb370745f499ece85697d11f51":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f6229f3640eb437baa4b6d844071fd93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"eabbdab3a77c40fb9dd312447b81d0a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c74ecfec7fa9436ba7ad95ea66d147a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dM8-pYQ0sX5V","executionInfo":{"status":"ok","timestamp":1609791734128,"user_tz":-540,"elapsed":7048,"user":{"displayName":"­이자연(엘텍공과대학 휴먼기계바이오공학부)","photoUrl":"","userId":"01890535783272153324"}},"outputId":"248709f4-77a2-4ef2-e87a-ca1fd1112cc3"},"source":["!pip install --upgrade transformers"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n","\u001b[K     |████████████████████████████████| 1.5MB 7.7MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n","Requirement already satisfied, skipping upgrade: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 29.3MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n","Collecting tokenizers==0.9.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 39.5MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n","Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=070151898ae93f9739f929209e6256b80df21456c4a5db3a00df2d749f1d00b9\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, tokenizers, transformers\n","Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o0hXVdZ3sMOQ","executionInfo":{"status":"ok","timestamp":1609791742975,"user_tz":-540,"elapsed":7228,"user":{"displayName":"­이자연(엘텍공과대학 휴먼기계바이오공학부)","photoUrl":"","userId":"01890535783272153324"}}},"source":["import tensorflow as tf\r\n","import numpy as np\r\n","import pandas as pd\r\n","from transformers import *\r\n","import json\r\n","import numpy as np\r\n","import pandas as pd\r\n","from tqdm import tqdm\r\n","import os\r\n","\r\n","#추가\r\n","import torch\r\n","\r\n","from transformers import BertTokenizer\r\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\r\n","from transformers import get_linear_schedule_with_warmup\r\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\r\n","from keras.preprocessing.sequence import pad_sequences\r\n","from sklearn.model_selection import train_test_split\r\n","\r\n","import pandas as pd\r\n","import numpy as np\r\n","import random\r\n","import time\r\n","import datetime"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"zGUvebaZsScA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609791768357,"user_tz":-540,"elapsed":29761,"user":{"displayName":"­이자연(엘텍공과대학 휴먼기계바이오공학부)","photoUrl":"","userId":"01890535783272153324"}},"outputId":"2d82074d-9411-49fd-94b1-bbb84d2047f8"},"source":["## Load data\r\n","from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YFUZwR3H3QLR","executionInfo":{"status":"ok","timestamp":1609791770062,"user_tz":-540,"elapsed":6056,"user":{"displayName":"­이자연(엘텍공과대학 휴먼기계바이오공학부)","photoUrl":"","userId":"01890535783272153324"}}},"source":["train = pd.read_table(\"/content/drive/MyDrive/NLP_MZ/data/\"+\"train_large.txt\")\n","test = pd.read_table(\"/content/drive/MyDrive/NLP_MZ/data/\"+\"test_large.txt\")\n","\n","# train = pd.read_table(\"/content/drive/MyDrive/NLP_MZ/data/\"+\"train_mid.txt\")\n","# test = pd.read_table(\"/content/drive/MyDrive/NLP_MZ/data/\"+\"test_mid.txt\")\n","\n","# train = pd.read_table(\"/content/drive/MyDrive/NLP_MZ/data/\"+\"train_small.txt\")\n","# test = pd.read_table(\"/content/drive/MyDrive/NLP_MZ/data/\"+\"test_small.txt\")"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"ybpeN6RvsgHW","executionInfo":{"status":"ok","timestamp":1609791770067,"user_tz":-540,"elapsed":3746,"user":{"displayName":"­이자연(엘텍공과대학 휴먼기계바이오공학부)","photoUrl":"","userId":"01890535783272153324"}},"outputId":"5c9e9283-6db2-41be-86cd-2fda196dc0eb"},"source":["train.head()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>id</th>\n","      <th>label</th>\n","      <th>document</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>앞차 뒤에서 똑같이 가</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>앞차 뒤에서 따라가 달려</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>앞차보다 먼저 가지 말고 따라가</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>앞차랑 안전거리 유지하고 운행해</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>앞에 차랑 목적지가 좁으니까 따라서 가</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0  id  label               document\n","0           0   0      0           앞차 뒤에서 똑같이 가\n","1           1   1      0          앞차 뒤에서 따라가 달려\n","2           2   2      0      앞차보다 먼저 가지 말고 따라가\n","3           3   3      0      앞차랑 안전거리 유지하고 운행해\n","4           4   4      0  앞에 차랑 목적지가 좁으니까 따라서 가"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fb_y-3STtOjf","executionInfo":{"status":"ok","timestamp":1609791772782,"user_tz":-540,"elapsed":5722,"user":{"displayName":"­이자연(엘텍공과대학 휴먼기계바이오공학부)","photoUrl":"","userId":"01890535783272153324"}},"outputId":"73b48dfe-2769-47ec-e364-5af0e3e4f5f6"},"source":["!pip install sentencepiece"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n","\r\u001b[K     |▎                               | 10kB 27.1MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 16.4MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 14.0MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40kB 12.9MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51kB 8.6MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61kB 8.1MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 9.2MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81kB 10.1MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92kB 9.3MB/s eta 0:00:01\r\u001b[K     |███                             | 102kB 9.5MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112kB 9.5MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122kB 9.5MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133kB 9.5MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143kB 9.5MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153kB 9.5MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 174kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 245kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 276kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 358kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 389kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 440kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 471kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 481kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 501kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 512kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 532kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 542kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 552kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 563kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 573kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 583kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 604kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 614kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 634kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 645kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 655kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 675kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 686kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 696kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 706kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 716kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 727kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 737kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 747kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 757kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 768kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 778kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 788kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 808kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 819kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 829kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 849kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 860kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 870kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 880kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 890kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 901kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 911kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 921kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 931kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 942kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 952kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 962kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 983kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 993kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0MB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0MB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.0MB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0MB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0MB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1MB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1MB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.1MB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1MB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1MB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1MB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1MB 9.5MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.94\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rvgsAEXS3OKk","executionInfo":{"status":"ok","timestamp":1609791776625,"user_tz":-540,"elapsed":1501,"user":{"displayName":"­이자연(엘텍공과대학 휴먼기계바이오공학부)","photoUrl":"","userId":"01890535783272153324"}}},"source":["!pip freeze > requirements.txt"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"4SAbCPsFskkF","executionInfo":{"status":"ok","timestamp":1609791777209,"user_tz":-540,"elapsed":1893,"user":{"displayName":"­이자연(엘텍공과대학 휴먼기계바이오공학부)","photoUrl":"","userId":"01890535783272153324"}}},"source":["import logging\r\n","import os\r\n","import unicodedata\r\n","from shutil import copyfile\r\n","import sentencepiece as spm\r\n","from transformers import PreTrainedTokenizer\r\n"," \r\n"," \r\n","logger = logging.getLogger(__name__)\r\n"," \r\n","VOCAB_FILES_NAMES = {\"vocab_file\": \"tokenizer_78b3253a26.model\",\r\n","                     \"vocab_txt\": \"vocab.txt\"}\r\n"," \r\n","PRETRAINED_VOCAB_FILES_MAP = {\r\n","    \"vocab_file\": {\r\n","        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/tokenizer_78b3253a26.model\",\r\n","        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/tokenizer_78b3253a26.model\",\r\n","        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/tokenizer_78b3253a26.model\"\r\n","    },\r\n","    \"vocab_txt\": {\r\n","        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/vocab.txt\",\r\n","        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/vocab.txt\",\r\n","        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/vocab.txt\"\r\n","    }\r\n","}\r\n"," \r\n","PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {\r\n","    \"monologg/kobert\": 512,\r\n","    \"monologg/kobert-lm\": 512,\r\n","    \"monologg/distilkobert\": 512\r\n","}\r\n"," \r\n","PRETRAINED_INIT_CONFIGURATION = {\r\n","    \"monologg/kobert\": {\"do_lower_case\": False},\r\n","    \"monologg/kobert-lm\": {\"do_lower_case\": False},\r\n","    \"monologg/distilkobert\": {\"do_lower_case\": False}\r\n","}\r\n"," \r\n","SPIECE_UNDERLINE = u'▁'\r\n"," \r\n"," \r\n","class KoBertTokenizer(PreTrainedTokenizer):\r\n","\r\n","    vocab_files_names = VOCAB_FILES_NAMES\r\n","    pretrained_vocab_files_map = PRETRAINED_VOCAB_FILES_MAP\r\n","    pretrained_init_configuration = PRETRAINED_INIT_CONFIGURATION\r\n","    max_model_input_sizes = PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES\r\n"," \r\n","    def __init__(\r\n","            self,\r\n","            vocab_file,\r\n","            vocab_txt,\r\n","            do_lower_case=False,\r\n","            remove_space=True,\r\n","            keep_accents=False,\r\n","            unk_token=\"[UNK]\",\r\n","            sep_token=\"[SEP]\",\r\n","            pad_token=\"[PAD]\",\r\n","            cls_token=\"[CLS]\",\r\n","            mask_token=\"[MASK]\",\r\n","            **kwargs):\r\n","        super().__init__(\r\n","            unk_token=unk_token,\r\n","            sep_token=sep_token,\r\n","            pad_token=pad_token,\r\n","            cls_token=cls_token,\r\n","            mask_token=mask_token,\r\n","            **kwargs\r\n","        )\r\n"," \r\n","        # Build vocab\r\n","        self.token2idx = dict()\r\n","        self.idx2token = []\r\n","        with open(vocab_txt, 'r', encoding='utf-8') as f:\r\n","            for idx, token in enumerate(f):\r\n","                token = token.strip()\r\n","                self.token2idx[token] = idx\r\n","                self.idx2token.append(token)\r\n"," \r\n","       # self.max_len_single_sentence = self.model_max_length - 2  # take into account special tokens\r\n","       # self.max_len_sentences_pair = self.model_max_length - 3  # take into account special tokens\r\n"," \r\n","        self.do_lower_case = do_lower_case\r\n","        self.remove_space = remove_space\r\n","        self.keep_accents = keep_accents\r\n","        self.vocab_file = vocab_file\r\n","        self.vocab_txt = vocab_txt\r\n"," \r\n","        self.sp_model = spm.SentencePieceProcessor()\r\n","        self.sp_model.Load(vocab_file)\r\n"," \r\n","    @property\r\n","    def vocab_size(self):\r\n","        return len(self.idx2token)\r\n"," \r\n","    def __getstate__(self):\r\n","        state = self.__dict__.copy()\r\n","        state[\"sp_model\"] = None\r\n","        return state\r\n"," \r\n","    def __setstate__(self, d):\r\n","        self.__dict__ = d\r\n","        self.sp_model = spm.SentencePieceProcessor()\r\n","        self.sp_model.Load(self.vocab_file)\r\n"," \r\n","    def preprocess_text(self, inputs):\r\n","        if self.remove_space:\r\n","            outputs = \"\".join(inputs.strip().split())\r\n","        else:\r\n","            outputs = inputs\r\n","        outputs = outputs.replace(\"``\", '\"').replace(\"''\", '\"')\r\n"," \r\n","        if not self.keep_accents:\r\n","            outputs = unicodedata.normalize('NFKD', outputs)\r\n","            outputs = \"\".join([c for c in outputs if not unicodedata.combining(c)])\r\n","        if self.do_lower_case:\r\n","            outputs = outputs.lower()\r\n"," \r\n","        return outputs\r\n"," \r\n","    def _tokenize(self, text, return_unicode=True, sample=False):\r\n","\r\n","        text = self.preprocess_text(text)\r\n"," \r\n","        if not sample:\r\n","            pieces = self.sp_model.EncodeAsPieces(text)\r\n","        else:\r\n","            pieces = self.sp_model.SampleEncodeAsPieces(text, 64, 0.1)\r\n","        new_pieces = []\r\n","        for piece in pieces:\r\n","            if len(piece) > 1 and piece[-1] == str(\",\") and piece[-2].isdigit():\r\n","                cur_pieces = self.sp_model.EncodeAsPieces(piece[:-1].replace(SPIECE_UNDERLINE, \"\"))\r\n","                if piece[0] != SPIECE_UNDERLINE and cur_pieces[0][0] == SPIECE_UNDERLINE:\r\n","                    if len(cur_pieces[0]) == 1:\r\n","                        cur_pieces = cur_pieces[1:]\r\n","                    else:\r\n","                        cur_pieces[0] = cur_pieces[0][1:]\r\n","                cur_pieces.append(piece[-1])\r\n","                new_pieces.extend(cur_pieces)\r\n","            else:\r\n","                new_pieces.append(piece)\r\n"," \r\n","        return new_pieces\r\n"," \r\n","    def _convert_token_to_id(self, token):\r\n","       \r\n","        return self.token2idx.get(token, self.token2idx[self.unk_token])\r\n"," \r\n","    def _convert_id_to_token(self, index, return_unicode=True):\r\n","        \r\n","        return self.idx2token[index]\r\n"," \r\n","    def convert_tokens_to_string(self, tokens):\r\n","       \r\n","        out_string = \"\".join(tokens).replace(SPIECE_UNDERLINE, \" \").strip()\r\n","        return out_string\r\n"," \r\n","    def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\r\n","        \r\n","        if token_ids_1 is None:\r\n","            return [self.cls_token_id] + token_ids_0 + [self.sep_token_id]\r\n","        cls = [self.cls_token_id]\r\n","        sep = [self.sep_token_id]\r\n","        return cls + token_ids_0 + sep + token_ids_1 + sep\r\n"," \r\n","    def get_special_tokens_mask(self, token_ids_0, token_ids_1=None, already_has_special_tokens=False):\r\n"," \r\n","        if already_has_special_tokens:\r\n","            if token_ids_1 is not None:\r\n","                raise ValueError(\r\n","                    \"You should not supply a second sequence if the provided sequence of \"\r\n","                    \"ids is already formated with special tokens for the model.\"\r\n","                )\r\n","            return list(map(lambda x: 1 if x in [self.sep_token_id, self.cls_token_id] else 0, token_ids_0))\r\n"," \r\n","        if token_ids_1 is not None:\r\n","            return [1] + ([0] * len(token_ids_0)) + [1] + ([0] * len(token_ids_1)) + [1]\r\n","        return [1] + ([0] * len(token_ids_0)) + [1]\r\n"," \r\n","    def create_token_type_ids_from_sequences(self, token_ids_0, token_ids_1=None):\r\n","      \r\n","        sep = [self.sep_token_id]\r\n","        cls = [self.cls_token_id]\r\n","        if token_ids_1 is None:\r\n","            return len(cls + token_ids_0 + sep) * [0]\r\n","        return len(cls + token_ids_0 + sep) * [0] + len(token_ids_1 + sep) * [1]\r\n"," \r\n","    def save_vocabulary(self, save_directory):\r\n","\r\n","        if not os.path.isdir(save_directory):\r\n","            logger.error(\"Vocabulary path ({}) should be a directory\".format(save_directory))\r\n","            return\r\n"," \r\n","        # 1. Save sentencepiece model\r\n","        out_vocab_model = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_file\"])\r\n"," \r\n","        if os.path.abspath(self.vocab_file) != os.path.abspath(out_vocab_model):\r\n","            copyfile(self.vocab_file, out_vocab_model)\r\n"," \r\n","        # 2. Save vocab.txt\r\n","        index = 0\r\n","        out_vocab_txt = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_txt\"])\r\n","        with open(out_vocab_txt, \"w\", encoding=\"utf-8\") as writer:\r\n","            for token, token_index in sorted(self.token2idx.items(), key=lambda kv: kv[1]):\r\n","                if index != token_index:\r\n","                    logger.warning(\r\n","                        \"Saving vocabulary to {}: vocabulary indices are not consecutive.\"\r\n","                        \" Please check that the vocabulary is not corrupted!\".format(out_vocab_txt)\r\n","                    )\r\n","                    index = token_index\r\n","                writer.write(token + \"\\n\")\r\n","                index += 1\r\n"," \r\n","        return out_vocab_model, out_vocab_txt\r\n"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"1sfI4rE4tXYx","colab":{"base_uri":"https://localhost:8080/","height":117,"referenced_widgets":["8bd049ceebfa4a64a062245aeaddc8f5","4c1592caa0d44faeb4e8feb682bdb235","aa960860c4b0475d85d7806ce57978be","a458ff71e9ab46cca01bffa14d8116f8","144fc1a1ebd54cd0b278bf95cd7fbd06","84906ccc049749868b0804275cea0753","1a1b35739c9e4e0abee8646c1eb0d2aa","e56ff34d68db4abe9b13332c9ee21cf5","88f4d4d2a1e3458fb77c6ae1bf99f397","9863fc90085a497aa466aead5289e4cf","a3726900e24b442e874e509a712f2c22","23e6cd0801e84695b377005559e0e681","460f1395d6e34bb08f482943f1fd8002","d606f82bc41f4e74bf48550f11b0f8d7","ef47f9f8bea04f95b624f2be80e0f9d7","b6b0af86de524f90bd99bba20d02bc86"]},"executionInfo":{"status":"ok","timestamp":1609791779689,"user_tz":-540,"elapsed":2728,"user":{"displayName":"­이자연(엘텍공과대학 휴먼기계바이오공학부)","photoUrl":"","userId":"01890535783272153324"}},"outputId":"1c0942de-b1a5-47c6-b81e-c9adc841123a"},"source":["#tokenizer = KoBertTokenizer.from_pretrained('monologg/kobert') \r\n","\r\n","tokenizer = BertTokenizer.from_pretrained('beomi/kcbert-large')"],"execution_count":11,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8bd049ceebfa4a64a062245aeaddc8f5","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=249928.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"88f4d4d2a1e3458fb77c6ae1bf99f397","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=49.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DVJ2lTOpIf7L","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1609791782335,"user_tz":-540,"elapsed":901,"user":{"displayName":"­이자연(엘텍공과대학 휴먼기계바이오공학부)","photoUrl":"","userId":"01890535783272153324"}},"outputId":"f938f39a-ad9f-4c83-ce75-d984d78406f1"},"source":["\"\"\"\r\n","#KoElectra\r\n","from transformers import ElectraTokenizer\r\n","\r\n","tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")\r\n","\"\"\""],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\n#KoElectra\\nfrom transformers import ElectraTokenizer\\n\\ntokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")\\n'"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"osZuj0D1taBa","executionInfo":{"status":"ok","timestamp":1609791802300,"user_tz":-540,"elapsed":18801,"user":{"displayName":"­이자연(엘텍공과대학 휴먼기계바이오공학부)","photoUrl":"","userId":"01890535783272153324"}},"outputId":"2a7aca76-7c10-4d35-ab6e-a9acf9c65bb2"},"source":["def convert_data(data_df):\r\n","    global tokenizer\r\n","    \r\n","    SEQ_LEN = 32 #SEQ_LEN : 버트에 들어갈 인풋의 길이\r\n","    \r\n","    tokens, masks, segments, targets = [], [], [], []\r\n","    \r\n","    for i in tqdm(range(len(data_df))):\r\n","        # token : 문장을 토큰화함\r\n","        token = tokenizer.encode(\"[CLS] \" + data_df[DATA_COLUMN][i] + \" [SEP]\", max_length=SEQ_LEN, pad_to_max_length=True)\r\n","       \r\n","        # 마스크는 토큰화한 문장에서 패딩이 아닌 부분은 1, 패딩인 부분은 0으로 통일\r\n","        num_zeros = token.count(0)\r\n","        mask = [1]*(SEQ_LEN-num_zeros) + [0]*num_zeros\r\n","        \r\n","        # 문장의 전후관계를 구분해주는 세그먼트는 문장이 1개밖에 없으므로 모두 0\r\n","        segment = [0]*SEQ_LEN\r\n"," \r\n","        # 버트 인풋으로 들어가는 token, mask, segment를 tokens, segments에 각각 저장\r\n","        tokens.append(token)\r\n","        masks.append(mask)\r\n","        segments.append(segment)\r\n","        \r\n","        # 정답(긍정 : 1 부정 0)을 targets 변수에 저장해 줌\r\n","        targets.append(data_df[LABEL_COLUMN][i])\r\n"," \r\n","    # tokens, masks, segments, 정답 변수 targets를 numpy array로 지정    \r\n","    tokens = np.array(tokens)\r\n","    print(tokens.shape)\r\n","    masks = np.array(masks)\r\n","    segments = np.array(segments)\r\n","    targets = np.array(targets)\r\n"," \r\n","    return [tokens, masks, segments], targets\r\n"," \r\n","# 위에 정의한 convert_data 함수를 불러오는 함수를 정의\r\n","def load_data(pandas_dataframe):\r\n","    data_df = pandas_dataframe\r\n","    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\r\n","    data_df[LABEL_COLUMN] = data_df[LABEL_COLUMN].astype(int)\r\n","    data_x, data_y = convert_data(data_df)\r\n","    return data_x, data_y\r\n"," \r\n","SEQ_LEN = 32\r\n","BATCH_SIZE = 32\r\n","# 긍부정 문장을 포함하고 있는 칼럼\r\n","DATA_COLUMN = \"document\"\r\n","# 긍정인지 부정인지를 (1=긍정,0=부정) 포함하고 있는 칼럼\r\n","LABEL_COLUMN = \"label\"\r\n"," \r\n","# train 데이터를 버트 인풋에 맞게 변환\r\n","train_x, train_y = load_data(train)\r\n"],"execution_count":13,"outputs":[{"output_type":"stream","text":["  0%|          | 0/83707 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","100%|██████████| 83707/83707 [00:17<00:00, 4857.15it/s]"],"name":"stderr"},{"output_type":"stream","text":["(83707, 32)\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oo0EvSGsvX6H","executionInfo":{"status":"ok","timestamp":1609791806596,"user_tz":-540,"elapsed":3042,"user":{"displayName":"­이자연(엘텍공과대학 휴먼기계바이오공학부)","photoUrl":"","userId":"01890535783272153324"}},"outputId":"8948fb9d-192b-47d2-888c-1dbe34d5513e"},"source":["test_x, test_y = load_data(test)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["  0%|          | 0/9228 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","100%|██████████| 9228/9228 [00:01<00:00, 5072.85it/s]"],"name":"stderr"},{"output_type":"stream","text":["(9228, 32)\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sryVsaWSDAtH","executionInfo":{"status":"ok","timestamp":1609791807977,"user_tz":-540,"elapsed":1435,"user":{"displayName":"­이자연(엘텍공과대학 휴먼기계바이오공학부)","photoUrl":"","userId":"01890535783272153324"}},"outputId":"a22519bd-db12-4aa6-9929-3a853b854862"},"source":["print(type(train_x[0]))\r\n","print(train_x[0].shape)\r\n","\r\n","train_inputs = torch.Tensor(train_x[0])\r\n","train_labels = torch.Tensor(train_y).type(torch.LongTensor)\r\n","train_masks = torch.Tensor(train_x[1])\r\n","validation_inputs = torch.Tensor(test_x[0])\r\n","validation_labels = torch.Tensor(test_y).type(torch.LongTensor)\r\n","validation_masks = torch.Tensor(test_x[1])\r\n","\r\n","print(train_inputs[0])\r\n","print(train_labels[0])\r\n","print(train_masks[0])\r\n","print(validation_inputs[0])\r\n","print(validation_labels[0])\r\n","print(validation_masks[0])"],"execution_count":15,"outputs":[{"output_type":"stream","text":["<class 'numpy.ndarray'>\n","(83707, 32)\n","tensor([2.0000e+00, 2.0000e+00, 2.1930e+03, 4.4950e+03, 1.1764e+04, 9.3270e+03,\n","        1.9700e+02, 3.0000e+00, 3.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","        0.0000e+00, 0.0000e+00])\n","tensor(0)\n","tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([2.0000e+00, 2.0000e+00, 6.0900e+02, 1.1310e+04, 8.0320e+03, 2.8390e+03,\n","        8.2490e+03, 2.7858e+04, 3.0000e+00, 3.0000e+00, 0.0000e+00, 0.0000e+00,\n","        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n","        0.0000e+00, 0.0000e+00])\n","tensor(0)\n","tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1sza37SXEF1i","executionInfo":{"status":"ok","timestamp":1609791813752,"user_tz":-540,"elapsed":833,"user":{"displayName":"­이자연(엘텍공과대학 휴먼기계바이오공학부)","photoUrl":"","userId":"01890535783272153324"}}},"source":["# 배치 사이즈\r\n","batch_size = 32\r\n","\r\n","# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\r\n","# 학습시 배치 사이즈 만큼 데이터를 가져옴\r\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\r\n","train_sampler = RandomSampler(train_data)\r\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\r\n","\r\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\r\n","validation_sampler = SequentialSampler(validation_data)\r\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mM-5YUTVEqvt","executionInfo":{"status":"ok","timestamp":1609791820641,"user_tz":-540,"elapsed":6377,"user":{"displayName":"­이자연(엘텍공과대학 휴먼기계바이오공학부)","photoUrl":"","userId":"01890535783272153324"}},"outputId":"567a7299-420a-4f8b-b938-db547ac17bca"},"source":["# GPU 디바이스 이름 구함\r\n","device_name = tf.test.gpu_device_name()\r\n","\r\n","# GPU 디바이스 이름 검사\r\n","if device_name == '/device:GPU:0':\r\n","    print('Found GPU at: {}'.format(device_name))\r\n","else:\r\n","    raise SystemError('GPU device not found')\r\n","\r\n","# 디바이스 설정\r\n","if torch.cuda.is_available():    \r\n","    device = torch.device(\"cuda\")\r\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\r\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\r\n","else:\r\n","    device = torch.device(\"cpu\")\r\n","    print('No GPU available, using the CPU instead.')"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n","There are 1 GPU(s) available.\n","We will use the GPU: Tesla T4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":227,"referenced_widgets":["9dd9d8b532224501bed58ce9cf0388d3","b89b29e5626c427f8b4235470df3a2b7","edfc0a7ca7a04cec94d8f9053f93d33b","cceaacf04137468181a73bff4adca90c","ea9cadd1202d4cbf94fdb432dd522a5a","56693297792c422f94586c67e997c0f2","157314427389450eb82713915ef7cf63","263a3c2fd58b43ad832eaf46feaa7168","3e2d035e75444449adda2c9a58b8246a","93f653834c8a415a9e187d563a4fbf00","7cdb3315d6e245268e1ef3eef44b865a","46fc8ec5195e4ccda0c60e62ed62e3ed","44686ceb370745f499ece85697d11f51","f6229f3640eb437baa4b6d844071fd93","eabbdab3a77c40fb9dd312447b81d0a5","c74ecfec7fa9436ba7ad95ea66d147a5"]},"id":"XLlQ672kEvHd","executionInfo":{"status":"ok","timestamp":1609791848446,"user_tz":-540,"elapsed":28130,"user":{"displayName":"­이자연(엘텍공과대학 휴먼기계바이오공학부)","photoUrl":"","userId":"01890535783272153324"}},"outputId":"13439642-aa75-4a9a-98cc-dbbb17672a01"},"source":["# 분류를 위한 BERT 모델 생성\r\n","model = BertForSequenceClassification.from_pretrained('beomi/kcbert-large', num_labels=784)"],"execution_count":18,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9dd9d8b532224501bed58ce9cf0388d3","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=672.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3e2d035e75444449adda2c9a58b8246a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1341992121.0, style=ProgressStyle(descr…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at beomi/kcbert-large were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-large and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Eu1ahVnMFBp7","executionInfo":{"status":"ok","timestamp":1609791848447,"user_tz":-540,"elapsed":23177,"user":{"displayName":"­이자연(엘텍공과대학 휴먼기계바이오공학부)","photoUrl":"","userId":"01890535783272153324"}}},"source":["# 옵티마이저 설정\r\n","optimizer = AdamW(model.parameters(),\r\n","                  lr = 2e-5, # 학습률\r\n","                  eps = 1e-8, # 0으로 나누는 것을 방지하기 위한 epsilon 값\r\n","                  weight_decay = 0.0001\r\n","                )\r\n","\r\n","# 에폭수\r\n","epochs = 20\r\n","\r\n","# 총 훈련 스텝 : 배치반복 횟수 * 에폭\r\n","total_steps = len(train_dataloader) * epochs\r\n","\r\n","# 처음에 학습률을 조금씩 변화시키는 스케줄러 생성\r\n","scheduler = get_linear_schedule_with_warmup(optimizer, \r\n","                                            num_warmup_steps = 0,\r\n","                                            num_training_steps = total_steps)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"RBJBZCKZFS6L","executionInfo":{"status":"ok","timestamp":1609791848448,"user_tz":-540,"elapsed":22903,"user":{"displayName":"­이자연(엘텍공과대학 휴먼기계바이오공학부)","photoUrl":"","userId":"01890535783272153324"}}},"source":["# 정확도 계산 함수\r\n","def flat_accuracy(preds, labels):\r\n","    \r\n","    pred_flat = np.argmax(preds, axis=1).flatten()\r\n","    labels_flat = labels.flatten()\r\n","\r\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\r\n","\r\n","# 시간 표시 함수\r\n","def format_time(elapsed):\r\n","\r\n","    # 반올림\r\n","    elapsed_rounded = int(round((elapsed)))\r\n","    \r\n","    # hh:mm:ss으로 형태 변경\r\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":448},"id":"-i6_GqSrFYhU","executionInfo":{"status":"error","timestamp":1609791875878,"user_tz":-540,"elapsed":24642,"user":{"displayName":"­이자연(엘텍공과대학 휴먼기계바이오공학부)","photoUrl":"","userId":"01890535783272153324"}},"outputId":"92f23932-3ec3-4061-b9f9-945d9819568f"},"source":["# 재현을 위해 랜덤시드 고정\r\n","seed_val = 42\r\n","random.seed(seed_val)\r\n","np.random.seed(seed_val)\r\n","torch.manual_seed(seed_val)\r\n","torch.cuda.manual_seed_all(seed_val)\r\n","\r\n","# 그래디언트 초기화\r\n","model.zero_grad()\r\n","model.to(device)\r\n","\r\n","checkpoint_last_path = '/content/drive/MyDrive/NLP_MZ/checkpoints_jy/kcbert_last_lbl.pth'\r\n","checkpoint_best_path = '/content/drive/MyDrive/NLP_MZ/checkpoints_jy/kcbert_best_lbl.pth'\r\n","best_acc = 0.0\r\n","\r\n","\r\n","# 에폭만큼 반복\r\n","for epoch_i in range(0, epochs):\r\n","    \r\n","    # ========================================\r\n","    #               Training\r\n","    # ========================================\r\n","    \r\n","    print(\"\")\r\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\r\n","    print('Training...')\r\n","\r\n","    # 시작 시간 설정\r\n","    t0 = time.time()\r\n","\r\n","    # 로스 초기화\r\n","    total_loss = 0\r\n","\r\n","    # 훈련모드로 변경\r\n","    model.train()\r\n","        \r\n","    # 데이터로더에서 배치만큼 반복하여 가져옴\r\n","    for step, batch in enumerate(train_dataloader):\r\n","        # 경과 정보 표시\r\n","        if step % 100 == 0 and not step == 0:\r\n","            elapsed = format_time(time.time() - t0)\r\n","            print('  Batch {:>5,}  of  {:>5,}. Loss: {:}    Elapsed: {:}.'.format(step, len(train_dataloader), total_loss/step, elapsed))\r\n","            torch.save(model.state_dict(), checkpoint_last_path)\r\n","            try :\r\n","                model.load_state_dict(torch.load(checkpoint_last_path))\r\n","            except : \r\n","                print('it failed to load checkpoint')\r\n","                raise KeyboardInterrupt\r\n","\r\n","        # 배치에서 데이터 추출, GPU 넣음\r\n","        b_input_ids, b_input_mask, b_labels = batch\r\n","        b_input_ids = b_input_ids.type(torch.LongTensor).to(device)\r\n","        b_input_mask =  b_input_mask.type(torch.LongTensor).to(device)\r\n","        b_labels = b_labels.type(torch.LongTensor).to(device)\r\n","\r\n","        # Forward 수행                \r\n","        outputs = model(b_input_ids, \r\n","                        token_type_ids=None, \r\n","                        attention_mask=b_input_mask, \r\n","                        labels=b_labels)\r\n","        \r\n","        # 로스 구함\r\n","        loss = outputs[0]\r\n","\r\n","        # 총 로스 계산\r\n","        total_loss += loss.item()\r\n","\r\n","        # Backward 수행으로 그래디언트 계산\r\n","        loss.backward()\r\n","\r\n","        # 그래디언트 클리핑\r\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\r\n","\r\n","        # 그래디언트를 통해 가중치 파라미터 업데이트\r\n","        optimizer.step()\r\n","\r\n","        # 스케줄러로 학습률 감소\r\n","        scheduler.step()\r\n","\r\n","        # 그래디언트 초기화\r\n","        model.zero_grad()\r\n","        \r\n","    # 평균 로스 계산\r\n","    avg_train_loss = total_loss / len(train_dataloader)            \r\n","\r\n","    print(\"\")\r\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\r\n","    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\r\n","        \r\n","    # ========================================\r\n","    #               Validation\r\n","    # ========================================\r\n","\r\n","    print(\"\")\r\n","    print(\"Running Validation...\")\r\n","\r\n","    #시작 시간 설정\r\n","    t0 = time.time()\r\n","\r\n","    # 평가모드로 변경\r\n","    model.eval()\r\n","\r\n","    # 변수 초기화\r\n","    eval_loss, eval_accuracy = 0, 0\r\n","    nb_eval_steps, nb_eval_examples = 0, 0\r\n","\r\n","    # 데이터로더에서 배치만큼 반복하여 가져옴\r\n","    for batch in validation_dataloader:\r\n","        \r\n","        # 배치에서 데이터 추출\r\n","        b_input_ids, b_input_mask, b_labels = batch\r\n","        b_input_ids = b_input_ids.type(torch.LongTensor).to(device)\r\n","        b_input_mask =  b_input_mask.type(torch.LongTensor).to(device)\r\n","        b_labels = b_labels.type(torch.LongTensor).to(device)\r\n","        \r\n","        # 그래디언트 계산 안함\r\n","        with torch.no_grad():     \r\n","            # Forward 수행\r\n","            outputs = model(b_input_ids, \r\n","                            token_type_ids=None, \r\n","                            attention_mask=b_input_mask)\r\n","        \r\n","        # 로스 구함\r\n","        logits = outputs[0]\r\n","\r\n","        # CPU로 데이터 이동\r\n","        logits = logits.detach().cpu().numpy()\r\n","        label_ids = b_labels.to('cpu').numpy()\r\n","        \r\n","        # 출력 로짓과 라벨을 비교하여 정확도 계산\r\n","        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\r\n","        eval_accuracy += tmp_eval_accuracy\r\n","        nb_eval_steps += 1\r\n","\r\n","    cur_acc = eval_accuracy/nb_eval_steps\r\n","    if best_acc < cur_acc : \r\n","        torch.save(model.state_dict(), checkpoint_best_path)\r\n","        best_acc = cur_acc\r\n","\r\n","    print(\"  Accuracy: {0:.8f}\".format(eval_accuracy/nb_eval_steps))\r\n","    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\r\n","\r\n","print(\"\")\r\n","print(\"Training complete!\")"],"execution_count":21,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 20 ========\n","Training...\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-c14361ea75ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# Backward 수행으로 그래디언트 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# 그래디언트 클리핑\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"odRJ6aGGMzWD"},"source":[],"execution_count":null,"outputs":[]}]}